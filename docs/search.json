[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "campr",
    "section": "",
    "text": "We chose The impact of Climate Change on society as part of monitoring SDG13 theme and we had 72 hours to deliver a) presentation explaining our solution; b) 10 mins video; c) code. This website stores our presentation, video, and code.\n\n\n\n\nThe image has been borrowed from the UN website: https://sdgs.un.org/goals/goal13\n\n\n\nBefore you dive into this website, you might want to have a look at the structure of the website and what to expect in each:\n\nHome tab is where you are right now!\nTeam tab is, well, about us ;)\nIntroduction tab introduces the theme and its significance\nData tab will tell you about the data we used and pre-processing it has undergone\nEDA tab is for exploratory data analysis\n\nWe really want to highlight that we aimed to produce reproducible code with good documentation, so you can replicate it and reuse for your own needs! If something doesn’t work – reach out, we will be grateful."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "campr",
    "section": "",
    "text": "Kristina Bratkova\nEric Wanjau\nGreta Timaite\n\nWe met each other while enjoying our time at Leeds Institute for Data Analytics, but we never got a chance to work on the same project! So, we thought this hackathon could be a fun opportunity to do it and also take a break from all-things-PhD :)\nOur motto (we just came up with this) is: Open data and tools for global problems."
  },
  {
    "objectID": "team.html",
    "href": "team.html",
    "title": "campr",
    "section": "",
    "text": "Greta (left), Kristina (center), and Eric (right) having the best time of their lives at the GISRUK 2022 conference ;)\n\n\n\nWe met each other while enjoying our time at Leeds Institute for Data Analytics, but we never got a chance to work on the same project! So, we thought this hackathon could be a fun opportunity to do it and also take a break from all-things-Master’s :)\nGreta Timaite is a 1+3 ESRC funded master’s student in Social Science Research at the University of Warwick. Previously she has been a part of Data Scientist Development Programme at Leeds Institute for Data Analytics (LIDA). Greta sometimes tweets as @GTimaite.\nKristina Bratkova is an MRes student at Lancaster University. Before this she was a part of the Data Scientist Development Programme at the Leeds Institute for Data Analytics (LIDA).\nEric Wanjau is an MRes student at University College London. Previously he was a part of the Data Scientist Development Programme at the Leeds Institute for Data Analytics (LIDA). You can find Eric on Twitter as @ericntay."
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "campr",
    "section": "",
    "text": "What are the consequences of climate change?\nAn increase in Earth’s yearly average temperature can have disastrous effects on humanity. As The Sustainable Development Goals Report 2022 summarise, climate change is “humanity’s”code red” warning” that has an impact on other sustainable development goals (SDG). For example, an increase in the frequency of natural disasters and extreme weather events, such as droughts and floods, will have a direct impact on food production leading to increased food insecurity. While climate change affects everyone, the already vulnerable populations (e.g. Central and South America) tend to be affected the most. Indeed, the research suggests that “climate-driven economic downturns” might increase the risk for conflict, especially in countries that depend on agriculture. As a result, this is likely to further perpetuate socioeconomic inequalities across populations and prevent the actualisation of the SDG goals.\n\n\n\n\nThe image has been borrowed from the UN website: https://sdgs.un.org/goals/goal13\n\n\n\n\n\nHow do people think about climate change?\nGiven the disastrous effects of climate change on humanity, it is not surprising that the the majority of people believe in climate change as a global emergency, even though there are regional variations. Indeed, experience of extreme weather events has been linked to changes in climate change attitudes and behaviours and personal concern for climate change have been associated with support for climate action and intervention.\n\n\nWhere does our project sit?\nHuman activity, such as burning fossil fuels, has significantly contributed to climate change. It has a negative impact on society through increased frequencies of climate-related natural disasters, such as drought or flood. Through exploratory data analysis we aim to examine the relationships between human activity and natural disasters. For example, is there a direct relationship between CO2 omissions and climate-related natural disasters? Is here a relationship between CO2 emissions and land temperature? What about CO2 emissions and renewable energy? An in-depth examination of such questions is beyond the scope of this project yet, exploratory data analysis (EDA), can support theory-generation that, then, might reveal causal relationships of the effects of climate change on society.\nSupport for climate action has also been associated with a personal perception of its consequences. Therefore, we are tried to examine the connection between personal belief in climate action, socioeconomic characteristics, and climate data. For instance, we asked if people with lower level of education prioritise economic growth because, likely, their income is lower compared to those who are more formally educated. Finally, we also tried to develop a model to predict support to climate action over economic growth in the hopes to better understand underlying causal mechanism."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "In this section the focus is on data sources used in the project:\n\nWhat data was used and why;\nHow were datasets processed;\nWhat problems and limitations were encountered and this might impact results;\n\nReproducibility: we used only open data and tools in this project to maximise reproducibility and promote open research. If one copy and pastes code from the code chunks in this document, it should be fully reproducible. Alternatively, one can examine R scripts corresponding to different parts of our analysis that can be found in this GitHub repository or https://github.com/GretaTimaite/UNBigDataHackathon2022\n\nData sources\nFor this project we used several datasets, which you can download from here:\n\nCO2 emissions per country;\nLand temperature per country;\nGDP per capita data;\nRenewable energy consumption (% of total final energy consumption);\nFrequencies of climate-related natural disasters;\nWorld data from {spData} package in R for country geometries;\nWorld Values Survey (WVS);\nOpenStreetMap (OSM) data\n\n\n\nGetting 1-6 data sources\nFirst we will download 1-6 data sources as listed above.\nSome of the data was provided by the Hackathon organisers, so exact source is unclear but they kindly allowed us to share them on GitHub. Thus, this is where we store the data.\nDo not forget to change the path to the file in the code below!!!\n\n# CO2 emissions data\nco2emissions = readxl::read_excel(\"data/CO2emissionsbycountry.xlsx\", # path to the file \n                                  skip = 2)\n\n# GDP per capita data \ngdp = readxl::read_excel(\"data/gdp.xls\", \n                         skip = 2)\n\n# Renewable energy consumption (% of total final energy consumption)\nrenewable_ec = readxl::read_excel(\"data/Renewable energy consumption (% of total final energy consumption).xlsx\",\n                                  skip = 2)\n\n# Frequencies of climate-related natural disasters\nclimate_disasters = readxl::read_excel(\"data/Climate-related_Disasters_Frequency.xlsx\")\n\n\n# Land temperatures\nland_temp = readr::read_csv(\"data/GlobalLandTemperaturesByCountry.csv\")\n\n# our world :)\nworld = spData::world\n\n\nSubsetting data\nWe will subset all data, so only data from 2000 to 2019 remains. The reason behind it that a number of countries do not have data prior, for example, 1990 as they part of the USSR and gained independence only after 1990. We think that data on the last 20 years will provide us enough longitudinal information.\nMoreover, we will drop some of the columns that will not serve us.\n\nco2emissions_clean = co2emissions |> \n  dplyr::select(c(1:2,45:64)) # select relevant columns\ncolnames(co2emissions_clean) = paste0(\"co2_\", colnames(co2emissions_clean)) # rename column names so we can identify them once joined with other datasets\n\ngdp_clean = gdp |> \n  dplyr::select(c(1:2,45:64))\ncolnames(gdp_clean) = paste0(\"gdp_\", colnames(gdp_clean))\n\nrenewable_clean = renewable_ec |> \n  dplyr::select(c(1:2,45:64))\ncolnames(renewable_clean) = paste0(\"ren_\", colnames(renewable_clean))\n\ndisasters_clean = climate_disasters |> \n  dplyr::filter(Indicator == \"Climate related disasters frequency, Number of Disasters: TOTAL\") |> # focus on total number of disasters\n  dplyr::select(c(2:4,32:51))\ncolnames(disasters_clean) = paste0(\"dis_\", colnames(disasters_clean))\n\n# land temperature data requires more attention...\n# we'll aggregate, so we have an average yearly temp instead of monthly, which is a bit too granular for our purposes\nland_temp_clean = land_temp |> \n  dplyr::mutate(year = lubridate::year(dt)) |> # extract year\n  dplyr::filter(year >= 2000 & year <=2019) |> # select data from 2000 to 2019\n  dplyr::group_by(Country, year) |> # group by country and year\n  dplyr::summarise(average_temp = mean(AverageTemperature)) |> # find out the average yearly temperature\n  tidyr::pivot_wider(names_from = year, values_from = average_temp) # reshape to wide format\ncolnames(land_temp_clean) = paste0(\"temp_\", colnames(land_temp_clean)) # give columns new names!\n\nNote: these datasets do not contain all the data that we would love to have. For example, land temperature dataset has records only up until 2013-09-01 (e.g. 2013). Thus, more recent data is missing and it has an impact on how much insight we can deliver. For example, if we are to examine the connection between land temperature and CO2 emissions, we would be able to do it up until 2013 even though we have data on CO2 emissions up to 2020.\n\n\nJoining data\nIn this section we will join all the data we have subsetted so far.\n\njoined_df = cbind(co2emissions_clean, gdp_clean, renewable_clean)  # Leave data on natural disasters aside for now\n\n# OK, let's drop some columns as they contain the same information\njoined_df_clean = joined_df |> \n  dplyr::select( -c(\"ren_Country Name\", \"ren_Country Code\", \"gdp_Country Name\", \"gdp_Country Code\"))\n\n# Join natural disasters data with our world\n# World data contains country's geometry shapes, thus allowing us to plot a map!\n# But first remove any NA values in ISO2 (we will use this column to join datasets)\nworld_clean_iso = world |>\n  dplyr::filter(!is.na(iso_a2)) # remove NAs in ISO\ndisasters_clean_iso = disasters_clean |> \n  dplyr::filter(!is.na(dis_ISO2)) # remove NAs in ISO\n# Left join\ndisasters_world = dplyr::left_join(world_clean_iso, disasters_clean_iso,\n                                   by = c(\"iso_a2\" = \"dis_ISO2\" ))\n\n# Left join with land temperature\ndis_temp = dplyr::left_join(disasters_world, land_temp_clean,\n                            by = c(\"name_long\" = \"temp_Country\"))\n\n# Let's plot disasters_world for sanity check (uncomment)\n# tmap::tm_shape(disasters_world) + \n#   tmap::tm_polygons(col = \"dis_F2019\")\n\n# now let's join all the datasets into one grand dataset :)\nclimate_action_data = dplyr::left_join(dis_temp, joined_df_clean,\n                                       by = c(\"dis_ISO3\" = \"co2_Country Code\"))\n# let's plot avergae yearly temperature in 2012!\ntmap::tm_shape(climate_action_data) + \n  tmap::tm_polygons(col = \"temp_2012\")\n\n\n\n\n\nAverage temperature in 2012\n\n\n\n\n\n\nData source 7 (World Values Survey)\nWorld Values Survey (WVS) is a global high-quality survey that collects nationally-representative data on values. The data is open to everyone to use for non-commercial purposes as long as data files themselves are not redistributed and correct citations provided. Given terms of use, we ask you to download data for waves 4-7 from their website and the recommended format is .sav (for SPSS).\n\n# read waves 4-7\nwvs4 = foreign::read.spss(\"data/WV4_Data_spss_v20201117.sav\",\n                          to.data.frame = TRUE) # import as dataframe (otherwise it will be a list)\nwvs5 = foreign::read.spss(\"data/WV5_Data_Spss_v20180912.sav\",\n                          to.data.frame = TRUE)\nwvs6 = foreign::read.spss(\"data/WV6_Data_sav_v20201117.sav\", \n                          to.data.frame = TRUE)\nwvs7 = foreign::read.spss(\"data/WVS_Cross-National_Wave_7_spss_v4_0.sav\", \n                          to.data.frame = TRUE)\n\n\nSubsetting\nEach WVS dataset has loads of variables, yet not all of them interest us at this point.\nWe will extract the following variables:\n\ncountry\nviews on the importance of protecting environment vs. economic growth (we use this question as a proxy for climate change attitude)\nsex (note: sex rather than gender is used in the surveys)\nage\neducation\nsocial class\nincome level\n\nAlso we will give more understandable column names.\n\nwvs7_sub = wvs7 |> dplyr::select(B_COUNTRY_ALPHA, Q111, Q260, X003R2, Q275R, Q287, Q288R)\ncolnames(wvs7_sub) = c(\"country_7\", \"env_7\", \"sex_7\", \"age_7\", \"education_7\", \"class_7\", \"income_7\")\n\nwvs6_sub = wvs6 |> dplyr::select(B_COUNTRY_ALPHA, V81, V240, X003R2, V248, V238, V239)\ncolnames(wvs6_sub) = c(\"country_6\", \"env_6\", \"sex_6\", \"age_6\", \"education_6\", \"class_6\", \"income_6\")\n\nwvs5_sub = wvs5 |> dplyr::select(V2, V104, V235, V237, V238, V252, V253) # I cannot believe this dataset doesn't have ISO code...\ncolnames(wvs5_sub) = c(\"country_5\", \"env_5\", \"sex_5\", \"age_5\", \"education_5\", \"class_5\", \"income_5\")\n\nwvs4_sub = wvs4 |> dplyr::select(B_COUNTRY_ALPHA, V36, V223, V225R2, V226, V235, V236)\ncolnames(wvs4_sub) = c(\"country_4\", \"env_4\", \"sex_4\", \"age_4\", \"education_4\", \"class_4\", \"income_4\")\n\n\n\nRecoding and joining\nIn this section we will change variable values from character to numeric in the hope of easing the interpretation. Then we will join all four waves into one dataset.\n\n# find out max length of each, we'll use this information to create NA cells, so length of all datasets is the same\n# then we'll be able to join them easily\n\nmax_length = max(c(nrow(wvs4_sub), nrow(wvs5_sub), nrow(wvs6_sub), nrow(wvs7_sub)))\nmax_length # wave 6 has most obervations\n\nwvs7_sub = wvs7_sub |> \n  dplyr::mutate (env_7_num = env_7 |> as.numeric(),\n                # env_7_num = c(wvs7_sub$env_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                sex_7_num = sex_7 |> as.numeric(),\n                # sex_7_num = c(wvs7_sub$sex_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                age_7_num = age_7 |> as.numeric(),\n                # age_7_num = c(wvs7_sub$age_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                education_7_num = education_7 |> as.numeric(),\n                # education_7_num = c(wvs7_sub$education_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                income_7_num = income_7 |> as.numeric(),\n                # income_7_num = c(wvs7_sub$income_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                )\n\nwvs7_new = data.frame(env_7_num = c(wvs7_sub$env_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                      sex_7_num = c(wvs7_sub$sex_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                      age_7_num = c(wvs7_sub$age_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                      education_7_num = c(wvs7_sub$education_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                      income_7_num = c(wvs7_sub$income_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                      country_7 = c(wvs7_sub$country_7, rep(NA, max_length - nrow(wvs7_sub)))\n                      )\n\nwvs6_sub = wvs6_sub |> \n  dplyr::mutate(env_6_num = env_6 |> as.numeric() |> as.factor(),\n                sex_6_num = sex_6 |> as.numeric(),\n                age_6_num = age_6 |> as.numeric(),\n                education_6_num = education_6 |> as.numeric(),\n                income_6_num = income_6 |> as.numeric())\n\nwvs6_new = data.frame(env_6_num = c(wvs6_sub$env_6_num, rep(NA, max_length - nrow(wvs6_sub))),\n                      sex_6_num = c(wvs6_sub$sex_6_num, rep(NA, max_length - nrow(wvs6_sub))),\n                      age_6_num = c(wvs6_sub$age_6_num, rep(NA, max_length - nrow(wvs6_sub))),\n                      education_6_num = c(wvs6_sub$education_6_num, rep(NA, max_length - nrow(wvs6_sub))),\n                      income_6_num = c(wvs6_sub$income_6_num, rep(NA, max_length - nrow(wvs6_sub))),\n                      country_6 = c(wvs6_sub$country_6, rep(NA, max_length - nrow(wvs6_sub)))\n)\n\nwvs5_sub = wvs5_sub |> \n  dplyr::mutate(env_5_num = env_5 |> as.numeric() |> as.factor(),\n                sex_5_num = sex_5 |> as.numeric(),\n                age_5_num = age_5 |> as.numeric() |> cut(breaks = c(0, 29, 49, 120), labels = c(1,2,3)),\n                education_5_num = education_5 |> as.numeric(),\n                income_5_num = income_5 |> as.numeric())\n\n# for some reason countries are returned as levels in integer form (e.g. 1) rather than character (i.e. \"Andora\"),\n# so we'll need to do tricks here :)\nunique_vals = wvs5_sub$country_5 |> unique() |> as.character()\nwvs5_new = data.frame(env_5_num = c(wvs5_sub$env_5_num, rep(NA, max_length - nrow(wvs5_sub))),\n                      sex_5_num = c(wvs5_sub$sex_5_num, rep(NA, max_length - nrow(wvs5_sub))),\n                      age_5_num = c(wvs5_sub$age_5_num, rep(NA, max_length - nrow(wvs5_sub))),\n                      education_5_num = c(wvs5_sub$education_5_num, rep(NA, max_length - nrow(wvs5_sub))),\n                      income_5_num = c(wvs5_sub$income_5_num, rep(NA, max_length - nrow(wvs5_sub))),\n                      country_5 = c(wvs5_sub$country_5, rep(NA, max_length - nrow(wvs5_sub))) |> factor(labels = unique_vals)\n)\n\n\nwvs4_sub = wvs4_sub |> \n  dplyr::mutate(env_4_num = env_4 |> as.numeric() |> as.factor(),\n                sex_4_num = sex_4 |> as.numeric(),\n                age_4_num = age_4 |> as.numeric(),\n                education_4_num = education_4 |> as.numeric(),\n                income_4_num = income_4 |> as.numeric())\n\nwvs4_new = data.frame(env_4_num = c(wvs4_sub$env_4_num, rep(NA, max_length - nrow(wvs4_sub))),\n                      sex_4_num = c(wvs4_sub$sex_4_num, rep(NA, max_length - nrow(wvs4_sub))),\n                      age_4_num = c(wvs4_sub$age_4_num, rep(NA, max_length - nrow(wvs4_sub))),\n                      education_4_num = c(wvs4_sub$education_4_num, rep(NA, max_length - nrow(wvs4_sub))),\n                      income_4_num = c(wvs4_sub$income_4_num, rep(NA, max_length - nrow(wvs4_sub))),\n                      country_4 = c(wvs4_sub$country_4, rep(NA, max_length - nrow(wvs4_sub)))\n)\n\n\n# sanity check that levels match numeric values (uncomment)\n# wvs7_sub$age_7 |> unique()\n# wvs7_sub$age_7_num |> unique()\n# wvs6_sub$age_6 |> unique()\n# wvs6_sub$age_6_num |> unique()\n# wvs5_sub$age_5 |> unique()\n# wvs5_sub$age_5_num |> unique()\n# wvs4_sub$age_4 |> unique()\n# wvs4_sub$age_4_num |> unique()\n\n\n\n\nData source 8 (OpenStreetMap)\nOpenStreetMap data is a global project aiming to create a free map of the world through crowdsourcing. It contains data on various data on buildings and roads. We used OSM data to collect the count of renewable energy generators. For historical data we relied on ohsome dashboard.\n\n\n\n\nAn example of retrieving the total count of renewable energy generators in Poland from 2007 to 2022\n\n\n\nIt is important to note that OSM data might not be complete, with some countries having more objects mapped that others. For example, developing countries, such as Iran, might have just started to consider the crowdsourced data and examine OSM data quality while in Germany the community of mappers is large. Also OSM developed as a road mapping project, therefore other objects (such as renewable energy generators) could have started being mapped later at different rates in different regions. Therefore, it is crucial to consider OSM data with a pinch of salt when analysing results. Nevertheless we still consider that OSM data can provide interesting insights and provide data that otherwise would not be freely and openly accessible.\n\n# import csv file containing OSM data\nosm = readxl::read_excel(\"data/osm.xlsx\")\n\n# let's extract year from the date\nosm_clean = osm |> \n  dplyr::mutate(year = lubridate::year(timestamp)\n                ) |> \n  dplyr::select(-1)\n\n# save our new osm dataset\n# write.csv(osm_clean,\n#           \"osm_clean.csv\")"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Exploratory data analysis (EDA) is an initial data investigation, that helps to inspect data and figure out what can (and cannot!) be done with data at hand, what trends can be observed and what statistical tests could be used (see “Data” section for information on data that we used).\nTherefore, this section is dedicated to data exploration! Moreover, in this section we used A LOT of data visualisations. Data visualisation can benefit EDA by injecting rigour as well as support inferences. Actually, some argue that the sharp distinction between exploratory and explanatory data analyses has started blurring as the size of datasets keeps increasing."
  },
  {
    "objectID": "eda.html#what-is-in-our-data",
    "href": "eda.html#what-is-in-our-data",
    "title": "Exploratory Data Analysis",
    "section": "What is in our data?",
    "text": "What is in our data?\nWe have discussed the benefits of EDA, but what is in the datasets we have chosen?\nOur data can be broadly defined as providing country-level data on climate and individual-level data on attitudes towards climate action and demographic characteristics. Therefore, for the clarity purposes, we will stick to this division for now :)\n\nCountry-level EDA\nWell, to answer these questions we created an interactive Shiny dashboard! Our goal is to ensure that not only we understand the data but also those who listen to our data stories. Indeed, interactive data visualisation is a great way to make data (and data science!) more accessible to everyone.\nIn the dashboard below you can visualise a variety of climate-related data by country over 20 years (2000-2019). For example, if you select Kenya and look at the “ren” (Renewable energy consumption (% of total final energy consumption)) variable, you will see a drop over the years… Why is it a case? And what might have caused this drop? Perhaps there was an increase in total energy consumption, so the reliance on fossil fuels increased?\n\n\nIndividual-level EDA\nThis subsecion will focus on World Values Survey data, which, as we mentioned in the “Data” section provides a representative sample for a number of countries.\n\n# Load awesomeness\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(here)\nlibrary(paletteer)\n\n# Load awesome data \n# If you loaded this data while going through \"Data\" section then you don't have to load it again!\n# We are just aiming to make each section able to stand on its own \nwvs <- read_csv(\"data/wvs.csv\")\ngeo_df <- st_read(\"data/climate_action_data.geojson\")\nosm <- read_csv(\"result.csv\")\n\n\nIs climate action more important than economic growth?\nIn the “Introduction” section we mentioned that people tend to agree that climate change is an emergency. We wanted to examine this too. Therefore, we used a question from WVS asking if environmental protection should be prioritised over economic growth as a proxy for peoples attitudes towards climate action. If an individual thinks that environment matters more, then there’s a positive attitude, otherwise a negative attitude is held.\nVisualisation below supports existing research and, indeed, in the last 20 years people (all countries considered) are more supportive towards climate change. The increase is really evident in the latest survey (Wave 7) which was carried out in 2017-2020.\n\ntheme_set(theme_light())\n# Explore how responses have changed over time\nenv_count <- wvs %>% \n  # Select evn columns\n  select(contains(\"env\")) %>% \n  #filter(if_any(everything(), is.na)) %>% \n  # Reshape data for easy analysis\n  pivot_longer(everything(), names_to = \"env\", values_to = \"opinion\") %>% \n#mutate(across(everything()))\n  # Drop missing values\n  drop_na() %>% \n  mutate(opinion = factor(opinion)) %>% \n  # Count number of respondents in each category\n  count(env, opinion) %>% \n  group_by(env) %>% \n  mutate(total = sum(n)) %>% \n  ungroup() %>% \n  mutate(pct = n/total) %>% \n  # Rename rows\n  mutate(env = case_when(\n    env == \"env_4_num\" ~ \"wave_4\",\n    env == \"env_5_num\" ~ \"wave_5\",\n    env == \"env_6_num\" ~ \"wave_6\",\n    env == \"env_7_num\" ~ \"wave_7\"\n  ))\n\n# Visualize this\nenv_count %>% \n  ggplot(mapping = aes(x = env, y = pct*100)) +\n  geom_col(aes(fill = opinion), position = \"dodge\", alpha = 0.8) +\n  paletteer::scale_fill_paletteer_d(\"ggthemes::Tableau_10\",\n                                    labels=c(\"protect environment\", \" Economic growth\", \"Other\")) +\n  ggtitle(\"Protecting environment vs Economic growth\") +\n  labs(x = \"survey period\",\n       y = \"% of respondents in survey\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\nA graph shows if respondents of all countries consider environmental protection as more important than economic growth"
  },
  {
    "objectID": "eda.html#country-level-eda",
    "href": "eda.html#country-level-eda",
    "title": "Exploratory Data Analysis",
    "section": "Country-level EDA",
    "text": "Country-level EDA\nTo answer data questions we created an interactive RShiny dashboard! Our goal is to ensure that not only we understand the data but also those who listen to our data stories. Indeed, interactive data visualisation is a great way to make data (and data science!) more accessible to everyone.\n\nHow has climate change-related country data changed over the years?\nIn the dashboard below (Figure 1; link in the image label) you can visualise a variety of climate-related data by country over 20 years (2000-2019). For example, if you select Kenya and look at the “ren” (Renewable energy consumption (% of total final energy consumption)) variable, you will see a drop over the years… Why is it a case? And what might have caused this drop? Perhaps there was an increase in total energy consumption, so the reliance on fossil fuels increased?\n\n\n\n\nFigure 1. R Shiny dashboard visualising climate data by country. URL: 6x2oh1-kika0.shinyapps.io/Dashboard\n\n\n\n\n\nWhere do countries stand in relation to each other?\nIn the previous subsection we explored climate-related data over time per country. It can show interesting trends, such as decreasing consumption of renewable energy in Kenya. But it might also be worthwhile to explore countries in relation to others. For example, the R Shiny Dashboard below (Figure 2; link in the image label) shows CO2 emissions in 2019. China and the United States emerge as two countries releasing the most CO2 emissions with China clearly leading the way. If you look at the CO2 emissions data from 2000 (co2_2000), China and the unites States still stand out but, back them, the US was the main producer of CO2 emissions. What happened during this time? Perhaps this change is a result of China’s economic development, but does this mean that it is also is the leading country for the consumption of renewable energy in 2019? Alas, no. Interestingly, African countries consume the most renewable energy (see ren_2019 variable).\n\n\n\n\nFigure 2. R Shiny dashboard mapping climate data. URL: 6x2oh1-kika0.shinyapps.io/Dashboard\n\n\n\nOn the other hand, we can see that the United States has remained, more or less, a leading country by the total number of renewable energy generators, while China is yet to catch up on this (Figure 3). Actually, the consumption of renewable energy has dropped in China (look at China in the EDA by Country). This is perhaps a result of increased economic activity, resulting in increased production of CO2 emissions but not expanding its renewable energy infrastructure.\nHowever, analysis of OSM data needs to be considered carefully as year-by-year change does not necessarily indicate how many new generators have been built. It might be a case that it used not to be a popular mapping object! For example, in 2007 there’s no data but it does not mean generators were not there. Finally, it needs to be mentioned that only about 50 countries are on the map for the pragmatic reasons – data for each country had to be downloaded seperately, thus making it a time-intensive activity. Therefore, we focused on countries that are also a part of WVS datasets, thus enabling some to join datasets to generate insights.\n\n\n\n\nFigure 3. R Shiny dashboard mapping the total number of renewable energy generators based on OpenMapStreet data. URL: 6x2oh1-kika0.shinyapps.io/Dashboard\n\n\n\n\n# This is a Shiny web application. You can run the application by clicking\n# the 'Run App' button above.\n#\n# Find out more about building applications with Shiny here:\n#\n#    http://shiny.rstudio.com/\n#\nlibrary(shinydashboard)\nlibrary(geojsonio)\nlibrary(sf)\nlibrary(dashboardthemes)\nlibrary(tmaptools)\nlibrary(ggplot2)\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(shinythemes)\nlibrary(viridis)\n#library(RColorBrewer)\n#library(fields)\n#library(ggsci)\nlibrary(paletteer)\nlibrary(RColorBrewer)\nlibrary(fields)\nlibrary(ggsci)\nlibrary(sf)\nlibrary(geojsonio)\nlibrary(tmap)\n# load data\nsfdf <- geojson_read(\"climate_action_data.geojson\",what=\"sp\") %>% st_as_sf()\n# read excel file for OSM data\nOSM = readxl::read_excel(\"osm.xlsx\") \nworld = spData::world\nOSM$timestamp <- substr(OSM$timestamp,0,4)\n#%>% rename(\"count_ren\"='0')\n# pivot_wider()\nOSM1 <- OSM %>% pivot_wider(names_from = timestamp)\n# join with world data \nOSM_sf <- world %>% select(name_long) %>%  left_join(OSM1,by=c(\"name_long\"=\"Country\")) \n# load data for WVS\nwvs <- read_csv(\"wvs.csv\")\nwv <- wvs %>% select(country_5) %>% left_join((sfdf %>% st_drop_geometry() %>% select(name_long,dis_ISO3)),by=(c(\"country_5\"=\"name_long\")))\n#sfdf20 <- sfdf[c(sample(1:nrow(sfdf),20)),]\n# Define UI for application that draws a histogram\nui <- dashboardPage(\n    dashboardHeader(title =tags$a(\"UNBigDataHackathon2022\", href=\"https://gretatimaite.github.io/campr/\",target=\"_blank\"),\n                    titleWidth=250),\n    dashboardSidebar(\n      width=250,\n      sidebarMenu(\n        \n        \n        menuItem(\"EDA by country\",tabName = \"widgets_together\"),\n        menuItem(\"EDA world map\",tabName = \"radioButtons_tmap\"),\n        menuItem(\"EDA WVS\",tabName = \"selectInput\"),\n        menuItem(\"EDA world renewables\",tabName = \"OSM\")\n    )\n    ),\n    dashboardBody(\n      shinyDashboardThemes(\n        theme = \"blue_gradient\"),\n      tabItems(\n        tabItem(tabName = \"selectInput\",\n                h1(\"World View Survey (WVS) data plotted per country\"),\n                h3(\"Is environmental protection more important than economic growth?\"),\n                fluidRow (\n                  selectInput(\"name1\",\n                              \"Select Country\",\n                              choices=(unique(wvs %>% select(country_4))),selected = \"ARG\"),\n                  \n                  \n                  fluidRow(plotOutput(outputId = \"wvs\")))\n                #mod_selectInput_ui(\"selectInput_1\")\n                ),\n        tabItem(tabName = \"widgets_together\",\n              h1(\"Plotted values for selected country of selected variables\"),\n              h3(\"Data is plotted for the 2000-2019 period (minus NA values that are country specific)\"),\n              p(\"Legend: ren (% of renewable energy), temp (average yearly temperature),\n                gdp(Total Gross Domestic product), dis (number of disasters), co2 (total CO2 emissions).\"),\n               #mod_widgets_together_ui(\"widgets_together_1\")\n               fluidRow (\n               selectInput(\"name\",\n                            \"Select Country\",\n                            choices=(unique(sfdf %>% st_drop_geometry() %>% select(name_long))),selected = \"Kenya\"),\n                selectInput(inputId=\"var\",\n                            label = \"Select y-axis variable\",\n                            choices=c(\"ren\",\"co2\",\"temp\",\"dis\",\"gdp\"),selected = \"ren\")\n        ,\n        fluidRow(plotOutput(outputId = \"regression_model\")))\n                ),\n        tabItem(tabName = \"radioButtons_tmap\",\n                h2(\"World map of selected variable\"),\n                tags$p(\"Legend: ren (% of renewable energy), temp (average yearly temperature),\n                gdp(Total Gross Domestic product), dis (number of disasters), co2 (total CO2 emissions).\"),\n                \n                radioButtons(inputId=\"vars\",label= NULL,inline=TRUE,\n                             choices = colnames(sfdf %>% as.data.frame() %>% select(starts_with(c(\"ren\",\"co2\",\"gdp\",\"temp\",\"dis\"))))),\n                fluidRow(\n                 h3(\"Choropleth map of variables\"),tmapOutput(outputId = \"map\")),\n                  \n            \n                #mod_radioButtons_tmap_ui(\"radioButtons_tmap_1\")\n                ),\n        tabItem(tabName = \"OSM\",\n                h2(\"World map of count of renewable energy generators\"),\n                tags$p(\"Count of generators per country per year.\"),\n                \n                radioButtons(inputId=\"year\",label= NULL,inline=TRUE,\n                             choices = colnames(OSM_sf %>% as.data.frame() %>% select(-c(name_long,geom)))),\n                fluidRow(\n                  h3(\"Choropleth map for selected year\"),\n                  tmapOutput(outputId = \"mapOSM\")),\n                \n                \n                #mod_radioButtons_tmap_ui(\"radioButtons_tmap_1\")\n        )\n      )))\n# Define server logic required to draw a histogram\nserver <- function(input, output) {\n  # mod_selectInput_server(\"selectInput_1\")\n  # mod_widgets_together_server(\"widgets_together_1\")\n  # mod_radioButtons_tmap_server(\"radioButtons_tmap_1\")\n# regression models\n  output$regression_model <- renderPlot({\n    \n    # t.c <- df_leeds %>% pull(sym!!(input$res_var))\n    # t.t <- df_leeds %>% pull(sym!!(input$lot_var))\n    #modeldensity_leeds <- data.frame(sfdf %>% pull(!!sym(input$res_var)),sfdf %>% pull(!!sym(input$lot_var)))\n    # fit regressions\n    \n    # sfdf20 %>% st_drop_geometry() %>% ggplot(aes(x=sfdf20 %>% pull(!!sym(input$res_var)),y=sfdf20 %>% pull(!!sym(input$lot_var)))) +\n    #   geom_smooth(method='lm') +\n    #   geom_point(alpha=0.5) +\n    #   xlab(input$res_var) +\n    #   ylab(input$lot_var) +\n    #   labs(title=paste0(\"Regression of \",input$res_var,\" and \",input$lot_var))\n    coln <- sfdf %>% filter(name_long==input$name) %>%  st_drop_geometry() %>% select(-c(dis_Country,dis_ISO3,co2_Country.Name,gdpPercap)) %>%\n      select(starts_with(c(input$var))) %>% names()\n    coln1 <- as.numeric(substr(coln,nchar(coln)-4+1,nchar(coln)))\n    values <- sfdf %>% st_drop_geometry() %>%filter(name_long==input$name) %>%  select(-c(dis_Country,dis_ISO3,co2_Country.Name,gdpPercap)) %>%\n      select(starts_with(c(input$var))) %>% unname() %>%  as_vector() \n    plot(x=coln1,y=values)\n    # library(stringr)\n    df <- data.frame(coln1,values)\n    ggplot(df) + geom_line(aes(x=coln1,y=values))  + geom_point(aes(x=coln1,y=values),lwd=2) +\n      xlab(input$var) +\n      \n      theme_minimal() \n  })\n  \n  output$map <- renderTmap({\n    tmap_options(basemaps = \"OpenStreetMap\")\n  \n    tm_shape(sfdf) +\n      tm_polygons(col= input$vars,palette=viridis(n=7),alpha = 0.5)\n  }) # end of renderTmap\n  \n  output$mapOSM <- renderTmap({\n    tmap_options(basemaps = \"OpenStreetMap\")\n    \n    tm_shape(OSM_sf) +\n      tm_polygons(col= input$year,palette=viridis(n=7),alpha = 0.5)\n  }) # end of renderTmap\n  # make tmap\n  \n  output$wvs <- renderPlot({\n    theme_set(theme_light())\n    # Explore how responses have changed over time\n    env_count <- wvs %>% \n      # Select evn columns\n      mutate(\"country_5\"=as_vector( wv[,2])) %>% \n      filter(country_5==input$name1 |country_4==input$name1 |country_6==input$name1 |country_7==input$name1  ) %>% \n      select(contains(\"env\")) %>% \n      #filter(if_any(everything(), is.na)) %>%  \n      # Reshape data for easy analysis\n      pivot_longer(everything(), names_to = \"env\", values_to = \"opinion\") %>% \n      #mutate(across(everything()))\n      # Drop missing values\n      drop_na() %>% \n      mutate(opinion = factor(opinion)) %>% \n      # Count number of respondents in each category\n      count(env, opinion) %>% \n      group_by(env) %>% \n      mutate(total = sum(n)) %>% \n      ungroup() %>% \n      mutate(pct = n/total) %>% \n      # Rename rows\n      mutate(env = case_when(\n        env == \"env_4_num\" ~ \"wave_4\",\n        env == \"env_5_num\" ~ \"wave_5\",\n        env == \"env_6_num\" ~ \"wave_6\",\n        env == \"env_7_num\" ~ \"wave_7\"\n      ))\n    \n    # Visualize this\n    env_count %>% \n      ggplot(mapping = aes(x = env, y = pct*100)) +\n      geom_col(aes(fill = opinion), position = \"dodge\", alpha = 0.8) +\n      paletteer::scale_fill_paletteer_d(\"ggthemes::Tableau_10\",\n                                        labels=c(\"protect environment\", \" Economic growth\", \"Other\")) +\n      ggtitle(\"Protecting environment vs Economic growth\") +\n      labs(x = \"survey period\",\n           y = \"% of respondents in survey\") +\n      theme(plot.title = element_text(hjust = 0.5))\n  })\n    \n}\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "eda.html#individual-level-eda",
    "href": "eda.html#individual-level-eda",
    "title": "Exploratory Data Analysis",
    "section": "Individual-level EDA",
    "text": "Individual-level EDA\nThis subsecion will focus on World Values Survey data, which, as we mentioned in the “Data” section, provides a representative sample for a number of countries.\n\n# Load awesomeness\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(here)\nlibrary(paletteer)\n\n# Load awesome data \n# If you loaded this data while going through \"Data\" section then you don't have to load it again!\n# We are just aiming to make each section able to stand on its own \nwvs <- read_csv(\"data/wvs.csv\")\ngeo_df <- st_read(\"data/climate_action_data.geojson\")\nosm <- read_csv(\"result.csv\")\n\n\nIs climate action more important than economic growth?\nIn the “Introduction” section we mentioned that people tend to agree that climate change is an emergency. We wanted to examine this too. Therefore, we used a question from WVS asking if environmental protection should be prioritised over economic growth as a proxy for peoples attitudes towards climate action. If an individual thinks that environment matters more, then there’s a positive attitude, otherwise a negative attitude is held.\nVisualisation in Figure 4 supports existing research and, indeed, in the last 20 years people (all countries considered) are more supportive towards climate change. The increase is really evident in the latest survey (Wave 7) which was carried out in 2017-2022.\n\n# Define cleaning function\nsel_mut <- function(df, col, new_col){\n  df %>% \n    select(contains(col)) %>% \n    mutate(wave = new_col) %>% \n    rename_with(~str_replace(.x, \"[:digit:]\", \"\") %>% str_remove(\"_\"))\n}\n\n\ntheme_set(theme_light())\n# Explore how responses have changed over time\nenv_count <- wvs %>% \n  # Select evn columns\n  select(contains(\"env\")) %>% \n  #filter(if_any(everything(), is.na)) %>% \n  # Reshape data for easy analysis\n  pivot_longer(everything(), names_to = \"env\", values_to = \"opinion\") %>% \n#mutate(across(everything()))\n  # Drop missing values\n  drop_na() %>% \n  mutate(opinion = factor(opinion)) %>% \n  # Count number of respondents in each category\n  count(env, opinion) %>% \n  group_by(env) %>% \n  mutate(total = sum(n)) %>% \n  ungroup() %>% \n  mutate(pct = n/total) %>% \n  # Rename rows\n  mutate(env = case_when(\n    env == \"env_4_num\" ~ \"wave_4\",\n    env == \"env_5_num\" ~ \"wave_5\",\n    env == \"env_6_num\" ~ \"wave_6\",\n    env == \"env_7_num\" ~ \"wave_7\"\n  ))\n\n# Visualize this\nenv_count %>% \n  ggplot(mapping = aes(x = env, y = pct*100)) +\n  geom_col(aes(fill = opinion), position = \"dodge\", alpha = 0.8) +\n  paletteer::scale_fill_paletteer_d(\"ggthemes::Tableau_10\",\n                                    labels=c(\"protect environment\", \" Economic growth\", \"Other\")) +\n  ggtitle(\"Protecting environment vs Economic growth\") +\n  labs(x = \"survey period\",\n       y = \"% of respondents in survey\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\nFigure 4. A graph shows if respondents of all countries consider environmental protection as more important than economic growth\n\n\n\nP.S. In the R Shiny dashboard you can also explore this quention on a country-level rather than aggregate data per wave.\n\n\nAge and climate change attitudes\nWhat demographic characteristics might shape attitudes towards the importance to protect environment rather than boost economic growth? We initially hypothesized that younger individuals are more supportive of climate action rather than older generation. Indeed, in Figure 5 we can observe similar trend – younger individuals prioritise economic protection over economic growth, yet this tends to vary from survey to sruvey, with a notable example of wave 6 conducted right after economic recession of 2007-2009.\n\n# Reshape data for easier analysis\ndf <- wvs %>%\n  sel_mut(col = \"4\", new_col = \"wave_4\") %>% \n  bind_rows(\n    sel_mut(wvs, col = \"5\", new_col = \"wave_5\")\n  ) %>%\n  bind_rows(\n    sel_mut(wvs, col = \"6\", new_col = \"wave_6\")\n  ) %>% \n  bind_rows(\n    sel_mut(wvs, col = \"7\", new_col = \"wave_7\")\n  ) %>% \n  rename(env_opinion = env_num) %>% \n  mutate(across(everything(), factor))\n\n\ndf %>% \n  count(wave, env_opinion, age_num) %>% \n  drop_na() %>%\n  group_by(age_num, wave) %>% \n  mutate(total = sum(n), pct = n/total) %>%\n  ungroup() %>% \n  mutate(age_num = case_when(\n    age_num == \"1\" ~ \"16-24\",\n    age_num == \"2\" ~ \"25-34\",\n    age_num == \"3\" ~ \"35-44\"\n  )) %>% \n  ggplot(mapping = aes(x = age_num, y = pct*100)) +\n  geom_col(aes(fill = env_opinion), position = \"dodge\", alpha = 0.8) +\n  paletteer::scale_fill_paletteer_d(\"ggthemes::Tableau_10\",\n                                    labels=c(\"protect environment\", \" Economic growth\", \"Other\")) +\n  ggtitle(\"Protecting environment vs Economic growth\") +\n  labs(x = \"age\",\n       y = \"% of respondents in survey\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  facet_wrap(vars(wave), scales = \"free_x\")\n\n\n\n\n\nFigure 5. A graph vsualises a relationship between age and support for environmental protection.\n\n\n\n\n\nIncome and climate change attitudes\nOur previous graph (Figure 5) hinted that perhaps personal and global economic situation has more effects on climate action views than age. Indeed, this is further supported by Figure 6 which shows respondent’s income level against economic growth vs environmental support variable. Indeed, in all waves people are more supportive of environmental protection with an exception of respondents with low income in wave 6, which, as it was mentioned, was conducted right after the economic recession.\n\n# Regroup income levels\ndf %>% \n  drop_na() %>% \n  mutate(income_num = as.numeric(income_num)) %>% \n  mutate(income = case_when(\n    income_num < 4 ~ \"low\",\n    income_num > 7 ~ \"high\",\n    TRUE ~ \"middle\"\n  ),\n  \n  \n  # Account for changes in wave7 encoding\n  income = case_when(\n    wave == \"wave_7\" & income_num == 1 ~ \"low\", \n    wave == \"wave_7\" & income_num == 2 ~ \"middle\",\n    wave == \"wave_7\" & income_num == 3 ~ \"high\",\n    TRUE ~ income\n  ),\n  \n  \n  income = factor(income, levels = c(\"high\", \"middle\", \"low\"))) %>%\n  # Count people in a wave sharing same income level and opinion\n  count(wave, env_opinion, income) %>% \n  # For people in a wave sharing the same income, what's their total\n  group_by(income, wave) %>% \n  # Find how opinion varies among folks sharing the same income \n  mutate(total = sum(n), pct = n/total) %>%\n  ungroup() %>% \n  ggplot(mapping = aes(x = income, y = pct*100)) +\n  geom_col(aes(fill = env_opinion), position = \"dodge\", alpha = 0.8) +\n  paletteer::scale_fill_paletteer_d(\"ggthemes::Tableau_10\",\n                                    labels=c(\"protect environment\", \" Economic growth\", \"Other\")) +\n  ggtitle(\"Protecting environment vs Economic growth\") +\n  labs(x = \"income_levels\",\n       y = \"% of respondents in survey\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  facet_wrap(vars(wave), scales = \"free_x\")\n\n\n\n\n\nFigure 6. A graph vsualises a relationship between income and support for environmental protection.\n\n\n\n\n\nEducation and climate change attitudes\nFinally, we looked into education. In the Peoples’ Climate Vote it is reported that education is the most significant factor behind views towards climate change – more educated individuals tend to recognise climate change as a global problem regardless of their country of origin. The results of the report align with the insights provided by Figure 7. It is clear that individuals with higher education (e.g. with Bachelor’s degree) are more supportive towards environmental protection.\n\ndf %>% \n  mutate(education_num = as.numeric(education_num)) %>% \n  mutate(education = case_when(\n    education_num < 3 ~ \"lower\",\n    education_num > 4 ~ \"higher\",\n    TRUE ~ \"middle\"\n  ),\n  \n  # Account for changes in wave7 encoding\n  education = case_when(\n    wave == \"wave_7\" & education_num == 2 ~ \"middle\", \n    wave == \"wave_7\" & education_num == 3 ~ \"higher\",\n    TRUE ~ education\n  ),\n  \n  \n  education = factor(education, levels = c(\"higher\", \"middle\", \"lower\"))) %>%\n  # Count people in a wave sharing same education level and opinion\n  count(wave, env_opinion, education) %>%\n  drop_na() %>% \n  # For people in a wave sharing the same education, what's their total\n  group_by(education, wave) %>% \n  # Find how opinion varies among folks sharing the same education level\n  mutate(total = sum(n), pct = n/total) %>%\n  ungroup() %>% \n  ggplot(mapping = aes(x = education, y = pct*100)) +\n  geom_col(aes(fill = env_opinion), position = \"dodge\", alpha = 0.8) +\n  paletteer::scale_fill_paletteer_d(\"ggthemes::Tableau_10\",\n                                    labels=c(\"protect environment\", \" Economic growth\", \"Other\")) +\n  ggtitle(\"Protecting environment vs Economic growth\") +\n  labs(x = \"education_levels\",\n       y = \"% of respondents in survey\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  facet_wrap(vars(wave), scales = \"free_x\")\n\n\n\n\n\nFigure 7. A graph vsualises a relationship between education and support for environmental protection."
  },
  {
    "objectID": "eda.html#final-comments",
    "href": "eda.html#final-comments",
    "title": "Exploratory Data Analysis",
    "section": "Final comments",
    "text": "Final comments\nIn this section we used interactive and static visualisations to explore the data and form some hypothesis of what might data might be telling us. For instance, we observed China emerging as a leading CO2 emissions producer over the last 20 years, yet it remains mediocre in terms of the number of renewable energy generators present in the country. Indeed, if you look, the total consumption of renewable energy has dropped in China. On the population level we noticed that there is a clear trend of more education people to support environmental protection. On the other hand, age and income provide less evident affects."
  },
  {
    "objectID": "model.html",
    "href": "model.html",
    "title": "Modelling",
    "section": "",
    "text": "We have used exploratory data analysis to better understand what data we have and what can be done with it. In this section we will focus on building a model to predict the support of environmental protection over economic growth.\nWe are doing this with support of tidymodels and XGBoost!"
  },
  {
    "objectID": "model.html#cleaning-data-for-modeling",
    "href": "model.html#cleaning-data-for-modeling",
    "title": "Modelling",
    "section": "Cleaning data for modeling",
    "text": "Cleaning data for modeling\n\nDo people living in areas with large usage of renewable energy have different opinions.\n\nlibrary(janitor)\n# Download open country code data\ncountry_codes <- read_csv(\"https://gist.githubusercontent.com/tadast/8827699/raw/f5cac3d42d16b78348610fc4ec301e9234f82821/countries_codes_and_coordinates.csv\", show_col_types = FALSE) %>% \n  clean_names() %>% \n  select(country, country_code = alpha_3_code, iso_a2 = alpha_2_code)\n\n# Left join this to data\ndf <- df %>% \n  rename(country_code = country) %>% \n  left_join(country_codes %>% select(-iso_a2), by = \"country_code\") %>% \n  # Account for NA values due to dataset mismatches\n  mutate(\n    country = replace_na(country, \"unknown\"),\n    country = case_when(\n    country == \"unknown\" ~ country_code,\n    TRUE ~ country\n  )) %>%\n  # Add iso_a2 column due to climate action data\n  left_join(country_codes %>% select(-country_code), by = \"country\")\n\n\n\nJoin data with climate action data\n\ndf %>% \n  left_join(ca_df %>% \n  select(iso_a2, contains(\"ren\")) %>% \n  st_drop_geometry() %>% \n  as_tibble() %>% \n  pivot_longer(!iso_a2, names_to = \"ren\", values_to = \"ren_val\") %>% \n  group_by(iso_a2) %>% \n  summarise(mean_ren = mean(ren_val), diff_ren = sum(diff(ren_val))),\n  by = \"iso_a2\") %>% \n  #mutate(mean_ren = mean(across(starts_with(\"ren\")))) %>% \n  ggplot()\n\n\nca_df %>% \n  select(iso_a2, contains(\"ren\")) %>% \n  st_drop_geometry() %>% \n  as_tibble() %>% \n  pivot_longer(!iso_a2, names_to = \"ren\", values_to = \"ren_val\") %>% \n  group_by(iso_a2) %>% \n  summarise(mean_ren = mean(ren_val), diff_ren = sum(diff(ren_val))) %>% View()\n\n\nfeature_summarize = function(tbl, feature){\n  tbl %>% \n    select(iso_a2, contains(feature)) %>% \n    pivot_longer(!iso_a2, names_to = \"feature\", values_to = \"val\") %>%\n    group_by(iso_a2) %>% \n    mutate(val = replace_na(val, mean(val, na.rm = TRUE))) %>% \n    group_by(iso_a2) %>% \n    summarise(val = sum(diff(val))) %>% \n    select(iso_a2, {{feature}} := val)\n    \n}\n\n\nca_df %>% filter(iso_a2 == \"KE\") %>% select(contains(\"temp\")) %>% st_drop_geometry() %>% slice(n = 1) %>% as.vector() %>% as.numeric()->xxc\n\nsum(diff(xxc))\n\n\nca_df %>% \n  st_drop_geometry() %>% \n  feature_summarize(feature = \"gdp_2\") %>% View()"
  },
  {
    "objectID": "model.html#do-people-living-in-areas-with-large-usage-of-renewable-energy-have-different-opinions",
    "href": "model.html#do-people-living-in-areas-with-large-usage-of-renewable-energy-have-different-opinions",
    "title": "Modelling",
    "section": "Do people living in areas with large usage of renewable energy have different opinions?",
    "text": "Do people living in areas with large usage of renewable energy have different opinions?\n\nlibrary(janitor)\n# Download open country code data\ncountry_codes <- read_csv(\"https://gist.githubusercontent.com/tadast/8827699/raw/f5cac3d42d16b78348610fc4ec301e9234f82821/countries_codes_and_coordinates.csv\", show_col_types = FALSE) %>% \n  clean_names() %>% \n  select(country, country_code = alpha_3_code, iso_a2 = alpha_2_code)\n# Left join this to data\ndf <- df %>% \n  rename(country_code = country) %>% \n  left_join(country_codes %>% select(-iso_a2), by = \"country_code\") %>% \n  # Account for NA values due to dataset mismatches\n  mutate(\n    country = replace_na(country, \"unknown\"),\n    country = case_when(\n    country == \"unknown\" ~ country_code,\n    TRUE ~ country\n  )) %>%\n  # Add iso_a2 column due to climate action data\n  left_join(country_codes %>% select(-country_code), by = \"country\")\n\n\nJoin data with climate action data\n\ndf %>% \n  left_join(ca_df %>% \n  select(iso_a2, contains(\"ren\")) %>% \n  st_drop_geometry() %>% \n  as_tibble() %>% \n  pivot_longer(!iso_a2, names_to = \"ren\", values_to = \"ren_val\") %>% \n  group_by(iso_a2) %>% \n  summarise(mean_ren = mean(ren_val), diff_ren = sum(diff(ren_val))),\n  by = \"iso_a2\") %>% \n  #mutate(mean_ren = mean(across(starts_with(\"ren\")))) %>% \n  ggplot()\n\n\nca_df %>% \n  select(iso_a2, contains(\"ren\")) %>% \n  st_drop_geometry() %>% \n  as_tibble() %>% \n  pivot_longer(!iso_a2, names_to = \"ren\", values_to = \"ren_val\") %>% \n  group_by(iso_a2) %>% \n  summarise(mean_ren = mean(ren_val), diff_ren = sum(diff(ren_val))) %>% View()\n\n\nfeature_summarize = function(tbl, feature){\n  tbl %>% \n    select(iso_a2, contains(feature)) %>% \n    pivot_longer(!iso_a2, names_to = \"feature\", values_to = \"val\") %>%\n    group_by(iso_a2) %>% \n    mutate(val = replace_na(val, mean(val, na.rm = TRUE))) %>% \n    group_by(iso_a2) %>% \n    summarise(val = sum(diff(val))) %>% \n    select(iso_a2, {{feature}} := val)\n    \n}\n\n\nca_df %>% filter(iso_a2 == \"KE\") %>% select(contains(\"temp\")) %>% st_drop_geometry() %>% slice(n = 1) %>% as.vector() %>% as.numeric()->xxc\nsum(diff(xxc))\n\n\nca_df %>% \n  st_drop_geometry() %>% \n  feature_summarize(feature = \"gdp_2\") %>% View()"
  },
  {
    "objectID": "model.html#xgboost",
    "href": "model.html#xgboost",
    "title": "Modelling",
    "section": "XGBOOST",
    "text": "XGBOOST\nThere are several steps to create a useful model, including parameter estimation, model selection and tuning, and performance assessment.\nFirst, is selecting the most appropriate variables for prediction.\nIn this section, we select the most appropriate variables based on previous EDA,\n\nca_dft <- ca_df %>% \n  st_drop_geometry() %>% \n  as_tibble()\nmodel_df <- df %>%\n  # Modify education\n  mutate(education_num = as.numeric(education_num)) %>% \n  mutate(education = case_when(\n    education_num < 3 ~ \"lower\",\n    education_num > 4 ~ \"higher\",\n    TRUE ~ \"middle\"\n  ),\n  \n  # Account for changes in wave7 encoding\n  education = case_when(\n    wave == \"wave_7\" & education_num == 2 ~ \"middle\", \n    wave == \"wave_7\" & education_num == 3 ~ \"higher\",\n    TRUE ~ education\n  ),\n  \n  \n  education = factor(education, levels = c(\"higher\", \"middle\", \"lower\"))) %>%\n  \n  # Modify income\n  drop_na() %>% \n  mutate(income_num = as.numeric(income_num)) %>% \n  mutate(income = case_when(\n    income_num < 4 ~ \"low\",\n    income_num > 7 ~ \"high\",\n    TRUE ~ \"middle\"\n  ),\n  \n  \n  # Account for changes in wave7 encoding\n  income = case_when(\n    wave == \"wave_7\" & income_num == 1 ~ \"low\", \n    wave == \"wave_7\" & income_num == 2 ~ \"middle\",\n    wave == \"wave_7\" & income_num == 3 ~ \"high\",\n    TRUE ~ income\n  ),\n  \n  \n  income = factor(income, levels = c(\"high\", \"middle\", \"low\"))) %>%\n  \n  # Modify age\n  mutate(age_num = case_when(\n    age_num == \"1\" ~ \"16-29\",\n    age_num == \"2\" ~ \"30-39\",\n    age_num == \"3\" ~ \"50 and above\"\n  )) %>%\n  \n  left_join(feature_summarize(ca_dft, \"ren\")) %>% \n  left_join(feature_summarize(ca_dft, \"dis_F\")) %>%  \n  left_join(feature_summarize(ca_dft, \"temp\")) %>% \n  left_join(feature_summarize(ca_dft, \"co2_2\")) %>%  \n  left_join(feature_summarize(ca_dft, \"gdp_2\")) %>% \n  left_join(ca_dft %>% select(iso_a2, lifeExp), by = \"iso_a2\") %>% \n  drop_na() %>% \n  filter(env_opinion != \"3\")\n\n\nFit xg_boost model\nFor the first part, data is split into two distinct sets, the training set and the test set. The training set (typically larger) is used to develop and optimize the model by fitting different models and investigating various feature engineering strategies etc.\nThe other portion of the data is the test set. This is held in reserve until one or two models are chosen as the methods that are most likely to succeed.\n\n# Load tidymodels and xgboost\nlibrary(tidymodels)\nlibrary(xgboost)\nset.seed(2056)\n# Split data\ndf_split <- model_df %>% \n  mutate(env_opinion = factor(env_opinion, levels = c(\"1\", \"2\"))) %>% \n  initial_split(prop = 0.75)\n# Extract train and test sets\ntrain = training(df_split)\ntest = testing(df_split)\nglue::glue(\n  'The training set has {nrow(train)} observations \\n',\n  'The testing set has {nrow(test)} observations'\n)\n# Create resamples for model assessment\ntrain_folds = vfold_cv(train, v = 3)\n\n\nCreate preprocessor\nFeature engineering entails reformatting predictor values to make them easier for a model to use effectively.\n\n# Function for prepping and baking a recipe\nprep_juice <- function(recipe){\n  recipe %>% \n    prep() %>% \n    juice()\n}\nboost_recipe <- recipe(\n  env_opinion ~ age_num + education + income + \n    ren + dis_F + temp +co2_2 +gdp_2+ lifeExp, data = train) %>% \n  # Pool infrequently occurring values into an \"other\" category.\n  step_other(age_num, threshold = 0.05) %>%\n  step_other(contains(\"age_num\"), threshold = 0.05) %>% \n  # Encode dummy variables\n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  # Near zero variance filter\n  step_nzv(all_predictors()) \n# Just for sanity check\n#View(prep_juice(boost_recipe))\n# Create boosted tree model specification\nboost_spec <- boost_tree(\n  #mtry = tune(),\n  trees = 50,\n  #min_n = tune(),\n  #tree_depth = tune(),\n  learn_rate = 0.01,\n  #loss_reduction = tune(),\n  #sample_size = tune(),\n  #stop_iter = tune()\n  ) %>% \n  set_engine(\"xgboost\") %>% \n  set_mode(\"classification\")\n# Bind recipe and model specification together\nboost_wf <- workflow() %>% \n  add_recipe(boost_recipe) %>% \n  add_model(boost_spec)\n# Print workflow\nboost_wf\n\n\n\n\nModel training\nBoosted tree models typically have tuning parameters or hyperparameters must be specified ahead of time and can't be directly found from training data. These are unknown structural or other kind of values that have significant impact on the model but cannot be directly estimated from the data. Instead, hyperparameters are estimated using simulated data sets created from a process called resampling such as cross-validation or bootstrap resampling.\n\ndoParallel::registerDoParallel()\nset.seed(2056)\n#library(finetune)\n# Evaluation metrics during tuning\neval_metrics <- metric_set(mn_log_loss, accuracy)\n# xgb_race <- tune_grid(boost_wf, resamples = train_folds, grid = 7, metrics = eval_metrics)\n# # Efficient grid search via racing\nxgb_race <- tune_race_anova(\n  object = boost_wf,\n  resamples = train_folds,\n  metrics = eval_metrics,\n  # Try out 20 different hyperparameter combinations\n  grid = 20,\n  control = control_race(\n    verbose_elim = TRUE\n  )\n)\n\n\n# Tibble with model with best accuracy\nxgb_race %>% \n  show_best(metric = \"accuracy\")\n\n\n# Train model\n# Train then test\n# Finalize workflow\nfinal_boost_wf <- boost_wf %>% \n  finalize_workflow(select_best(xgb_race, metric = \"mn_log_loss\" #mn_log_loss\n                    ))\n# Train then test\nxgb_model <- final_boost_wf %>% \n  last_fit(df_split, metrics = metric_set(accuracy, recall, spec, ppv, roc_auc, mn_log_loss, f_meas))\n# Collect metrics\nxgb_model %>% \n  collect_metrics()\n\n\n\n\nEvaluate model performance\n\n# Plot confusion matrix\nxgb_model %>% \n  collect_predictions() %>% \n  conf_mat(truth = env_opinion, estimate = .pred_class) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n# Prettier?\nupdate_geom_defaults(geom = \"rect\", new = list(fill = \"midnightblue\", alpha = 0.7))\nxgb_model %>% \n  collect_predictions() %>% \n  conf_mat(env_opinion, .pred_class) %>% \n  autoplot()\n\n\nThe performance metrics considered are:=\nRecall: TP/(TP + FN) defined as the proportion of positive results out of the number of samples which were actually positive. Also known as sensitivity.\nSpecificity: TN/(TN + FP) defined as the proportion of negative results out of the number of samples which were actually negative.\nPrecision: TP/(TP + FP) defined as the proportion of predicted positives that are actually positive. Also called positive predictive value\nAccuracy: TP + TN/(TP + TN + FP + FN) The percentage of labels predicted accurately for a sample.\n\n# Collect metrics\nxgb_model %>% \n  collect_metrics() %>% \n  filter(.metric %in% c(\"accuracy\", \"recall\", \"f_meas\", \"mn_log_loss\"))\n\nInsights from modeling results:\n\nThe model was able to correctly distinguish 60% of the respondents\nThe model has a high ability to accurately distinguish respondents who support climate action.\nF Measure: A weighted average of the precision and recall, with best being 1 and worst being 0.\n\nOverall, for only tuning the number of trees, the model performed quite decently."
  },
  {
    "objectID": "model.html#do-people-living-in-areas-with-large-usage-of-renewable-energy-have-different-opinions.",
    "href": "model.html#do-people-living-in-areas-with-large-usage-of-renewable-energy-have-different-opinions.",
    "title": "Modelling",
    "section": "Do people living in areas with large usage of renewable energy have different opinions.",
    "text": "Do people living in areas with large usage of renewable energy have different opinions.\n\nlibrary(janitor)\n# Download open country code data\ncountry_codes <- read_csv(\"https://gist.githubusercontent.com/tadast/8827699/raw/f5cac3d42d16b78348610fc4ec301e9234f82821/countries_codes_and_coordinates.csv\", show_col_types = FALSE) %>% \n  clean_names() %>% \n  select(country, country_code = alpha_3_code, iso_a2 = alpha_2_code)\n\n# Left join this to data\ndf <- df %>% \n  rename(country_code = country) %>% \n  left_join(country_codes %>% select(-iso_a2), by = \"country_code\") %>% \n  # Account for NA values due to dataset mismatches\n  mutate(\n    country = replace_na(country, \"unknown\"),\n    country = case_when(\n    country == \"unknown\" ~ country_code,\n    TRUE ~ country\n  )) %>%\n  # Add iso_a2 column due to climate action data\n  left_join(country_codes %>% select(-country_code), by = \"country\")\n\n\nJoin data with climate action data\n\ndf %>% \n  left_join(ca_df %>% \n  select(iso_a2, contains(\"ren\")) %>% \n  st_drop_geometry() %>% \n  as_tibble() %>% \n  pivot_longer(!iso_a2, names_to = \"ren\", values_to = \"ren_val\") %>% \n  group_by(iso_a2) %>% \n  summarise(mean_ren = mean(ren_val), diff_ren = sum(diff(ren_val))),\n  by = \"iso_a2\") %>% \n  #mutate(mean_ren = mean(across(starts_with(\"ren\")))) %>% \n  ggplot()\n\n\nca_df %>% \n  select(iso_a2, contains(\"ren\")) %>% \n  st_drop_geometry() %>% \n  as_tibble() %>% \n  pivot_longer(!iso_a2, names_to = \"ren\", values_to = \"ren_val\") %>% \n  group_by(iso_a2) %>% \n  summarise(mean_ren = mean(ren_val), diff_ren = sum(diff(ren_val))) %>% View()\n\n\nfeature_summarize = function(tbl, feature){\n  tbl %>% \n    select(iso_a2, contains(feature)) %>% \n    pivot_longer(!iso_a2, names_to = \"feature\", values_to = \"val\") %>%\n    group_by(iso_a2) %>% \n    mutate(val = replace_na(val, mean(val, na.rm = TRUE))) %>% \n    group_by(iso_a2) %>% \n    summarise(val = sum(diff(val))) %>% \n    select(iso_a2, {{feature}} := val)\n    \n}\n\n\nca_df %>% filter(iso_a2 == \"KE\") %>% select(contains(\"temp\")) %>% st_drop_geometry() %>% slice(n = 1) %>% as.vector() %>% as.numeric()->xxc\n\nsum(diff(xxc))\n\n\nca_df %>% \n  st_drop_geometry() %>% \n  feature_summarize(feature = \"gdp_2\") %>% View()"
  },
  {
    "objectID": "model.html#model-interpretability",
    "href": "model.html#model-interpretability",
    "title": "Modelling",
    "section": "Model interpretability",
    "text": "Model interpretability\nIn this section, we explore why the model makes the predictions it does.\n\noptions(scipen = 999)\n# Extract trained workflow\nxgb_wf <- xgb_model %>% \n  extract_workflow()\n# Extract variable importance\nlibrary(vip)\nvi <- xgb_wf %>% \n  extract_fit_parsnip() %>% \n  vi()\nvi\n\nLet’s visualize these model interpretability results\n\nvi %>% \n  slice_max(Importance, n = 42) %>%\n  mutate(Variable = fct_reorder(Variable, Importance)) %>%\n  ggplot(mapping = aes(y = Variable, x = Importance)) +\n  geom_point(size = 3, color = \"dodgerblue\") + \n  geom_segment(aes(y = Variable, yend = Variable, x = 0, xend = Importance), size = 2, color = \"dodgerblue\", alpha = 0.7 ) +\n  ggtitle(paste(\"Variable Importance plot of top\", round(nrow(vi)/2), \"variables\")) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n# SHAP for xgboost\nlibrary(SHAPforxgboost)\n# Prepare shap values for plotting. Requires a matrix\nopinion_shap <- shap.prep(\n  # Actual Boost engine\n  xgb_model = xgb_wf %>% \n    extract_fit_engine(),\n  # predictors used to calculate SHAP values\n  X_train = boost_recipe %>% \n    prep() %>% bake(has_role(\"predictor\"),\n                 new_data = NULL,\n                 composition = \"matrix\"),\n  top_n = 8\n  \n)\nshap.plot.summary(opinion_shap)"
  }
]