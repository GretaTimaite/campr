[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "campr",
    "section": "",
    "text": "We chose The impact of Climate Change on society as part of monitoring SDG13 theme and we had 72 hours to deliver a) presentation explaining our solution; b) 10 mins video; c) code. This website stores our presentation, video, and code.\n\n\n\n\nThe image has been borrowed from the UN website: https://sdgs.un.org/goals/goal13\n\n\n\nBefore you dive into this website, you might want to have a look at the structure of the website and what to expect in each:\n\nHome tab is where you are right now!\nTeam tab is, well, about us ;)\nIntroduction tab introduces the theme and its significance\nData tab will tell you about the data we used and pre-processing it has undergone\nEDA tab is for exploratory data analysis\n\nWe really want to highlight that we aimed to produce reproducible code with good documentation, so you can replicate it and reuse for your own needs! If something doesn’t work – reach out, we will be grateful."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "campr",
    "section": "",
    "text": "Kristina Bratkova\nEric Wanjau\nGreta Timaite\n\nWe met each other while enjoying our time at Leeds Institute for Data Analytics, but we never got a chance to work on the same project! So, we thought this hackathon could be a fun opportunity to do it and also take a break from all-things-PhD :)\nOur motto (we just came up with this) is: Open data and tools for global problems."
  },
  {
    "objectID": "team.html",
    "href": "team.html",
    "title": "campr",
    "section": "",
    "text": "Greta (left), Kristina (center), and Eric (right) having the best time of their lives at the GISRUK 2022 conference ;)\n\n\n\nWe met each other while enjoying our time at Leeds Institute for Data Analytics, but we never got a chance to work on the same project! So, we thought this hackathon could be a fun opportunity to do it and also take a break from all-things-Master’s :)\nOur motto (we just came up with this) is: Open data and tools for global problems."
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "campr",
    "section": "",
    "text": "What are the consequences of climate change?\nAn increase in Earth’s yearly average temperature can have disastrous effects on humanity. As The Sustainable Development Goals Report 2022 summarise, climate change is “humanity’s”code red” warning” that has an impact on other sustainable development goals (SDG). For example, an increase in the frequency of natural disasters and extreme weather events, such as droughts and floods, will have a direct impact on food production leading to increased food insecurity. While climate change affects everyone, the already vulnerable populations (e.g. Central and South America) tend to be affected the most. Indeed, the research suggests that “climate-driven economic downturns” might increase the risk for conflict, especially in countries that depend on agriculture. As a result, this is likely to further perpetuate socioeconomic inequalities across populations and prevent the actualisation of the SDG goals.\n\n\n\n\nThe image has been borrowed from the UN website: https://sdgs.un.org/goals/goal13\n\n\n\n\n\nHow do people think about climate change?\nGiven the disastrous effects of climate change on humanity, it is not surprising that the the majority of people believe in climate change as a global emergency, even though there are regional variations. Indeed, experience of extreme weather events has been linked to changes in climate change attitudes and behaviours and personal concern for climate change have been associated with support for climate action and intervention.\n\n\nWhere does our project sit?\nHuman activity, such as burning fossil fuels, has significantly contributed to climate change. It has a negative impact on society through increased frequencies of climate-related natural disasters, such as drought or flood. Through exploratory data analysis we aim to examine the relationships between human activity and natural disasters. For example, is there a direct relationship between CO2 omissions and climate-related natural disasters? Is here a relationship between CO2 emissions and land temperature? What about CO2 emissions and renewable energy? An in-depth examination of such questions is beyond the scope of this project yet, exploratory data analysis (EDA), can support theory-generation that, then, might reveal causal relationships of the effects of climate change on society.\nSupport for climate action has also been associated with a personal perception of its consequences. Therefore, we are also trying to examine the connection between personal belief in climate action, socioeconomic characteristics, and climate data. For instance, [run out of ideas..]"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "In this section the focus is on data sources used in the project:\n\nWhat data was used and why;\nHow were datasets processed;\nWhat problems and limitations were encountered and this might impact results;\n\nReproducibility: we used only open data and tools in this project to maximise reproducibility and promote open research. If one copy and pastes code from the code chunks in this document, it should be fully reproducible. Alternatively, one can examine R scripts corresponding to different parts of our analysis that can be found in this GitHub repository or https://github.com/GretaTimaite/UNBigDataHackathon2022\n\nData sources\nFor this project we used several datasets, which you can download from here:\n\nCO2 emissions per country;\nLand temperature per country;\nGDP per capita data;\nRenewable energy consumption (% of total final energy consumption);\nFrequencies of climate-related natural disasters;\nWorld data from {spData} package in R for country geometries;\nWorld Values Survey (WVS);\nOpenStreetMap (OSM) data\n\n\n\nGetting 1-6 data sources\nFirst we will download 1-6 data sources as listed above.\nSome of the data was provided by the Hackathon organisers, so exact source is unclear but they kindly allowed us to share them on GitHub. Thus, this is where we store the data.\nDo not forget to change the path to the file in the code below!!!\n\n# CO2 emissions data\nco2emissions = readxl::read_excel(\"data/CO2emissionsbycountry.xlsx\", # path to the file \n                                  skip = 2)\n\n# GDP per capita data \ngdp = readxl::read_excel(\"data/gdp.xls\", \n                         skip = 2)\n\n# Renewable energy consumption (% of total final energy consumption)\nrenewable_ec = readxl::read_excel(\"data/Renewable energy consumption (% of total final energy consumption).xlsx\",\n                                  skip = 2)\n\n# Frequencies of climate-related natural disasters\nclimate_disasters = readxl::read_excel(\"data/Climate-related_Disasters_Frequency.xlsx\")\n\n\n# Land temperatures\nland_temp = readr::read_csv(\"data/GlobalLandTemperaturesByCountry.csv\")\n\n# our world :)\nworld = spData::world\n\n\nSubsetting data\nWe will subset all data, so only data from 2000 to 2019 remains. The reason behind it that a number of countries do not have data prior, for example, 1990 as they part of the USSR and gained independence only after 1990. We think that data on the last 20 years will provide us enough longitudinal information.\nMoreover, we will drop some of the columns that will not serve us.\n\nco2emissions_clean = co2emissions |> \n  dplyr::select(c(1:2,45:64)) # select relevant columns\ncolnames(co2emissions_clean) = paste0(\"co2_\", colnames(co2emissions_clean)) # rename column names so we can identify them once joined with other datasets\n\ngdp_clean = gdp |> \n  dplyr::select(c(1:2,45:64))\ncolnames(gdp_clean) = paste0(\"gdp_\", colnames(gdp_clean))\n\nrenewable_clean = renewable_ec |> \n  dplyr::select(c(1:2,45:64))\ncolnames(renewable_clean) = paste0(\"ren_\", colnames(renewable_clean))\n\ndisasters_clean = climate_disasters |> \n  dplyr::filter(Indicator == \"Climate related disasters frequency, Number of Disasters: TOTAL\") |> # focus on total number of disasters\n  dplyr::select(c(2:4,32:51))\ncolnames(disasters_clean) = paste0(\"dis_\", colnames(disasters_clean))\n\n# land temperature data requires more attention...\n# we'll aggregate, so we have an average yearly temp instead of monthly, which is a bit too granular for our purposes\nland_temp_clean = land_temp |> \n  dplyr::mutate(year = lubridate::year(dt)) |> # extract year\n  dplyr::filter(year >= 2000 & year <=2019) |> # select data from 2000 to 2019\n  dplyr::group_by(Country, year) |> # group by country and year\n  dplyr::summarise(average_temp = mean(AverageTemperature)) |> # find out the average yearly temperature\n  tidyr::pivot_wider(names_from = year, values_from = average_temp) # reshape to wide format\ncolnames(land_temp_clean) = paste0(\"temp_\", colnames(land_temp_clean)) # give columns new names!\n\nNote: these datasets do not contain all the data that we would love to have. For example, land temperature dataset has records only up until 2013-09-01 (e.g. 2013). Thus, more recent data is missing and it has an impact on how much insight we can deliver. For example, if we are to examine the connection between land temperature and CO2 emissions, we would be able to do it up until 2013 even though we have data on CO2 emissions up to 2020.\n\n\nJoining data\nIn this section we will join all the data we have subsetted so far.\n\njoined_df = cbind(co2emissions_clean, gdp_clean, renewable_clean)  # Leave data on natural disasters aside for now\n\n# OK, let's drop some columns as they contain the same information\njoined_df_clean = joined_df |> \n  dplyr::select( -c(\"ren_Country Name\", \"ren_Country Code\", \"gdp_Country Name\", \"gdp_Country Code\"))\n\n# Join natural disasters data with our world\n# World data contains country's geometry shapes, thus allowing us to plot a map!\n# But first remove any NA values in ISO2 (we will use this column to join datasets)\nworld_clean_iso = world |>\n  dplyr::filter(!is.na(iso_a2)) # remove NAs in ISO\ndisasters_clean_iso = disasters_clean |> \n  dplyr::filter(!is.na(dis_ISO2)) # remove NAs in ISO\n# Left join\ndisasters_world = dplyr::left_join(world_clean_iso, disasters_clean_iso,\n                                   by = c(\"iso_a2\" = \"dis_ISO2\" ))\n\n# Left join with land temperature\ndis_temp = dplyr::left_join(disasters_world, land_temp_clean,\n                            by = c(\"name_long\" = \"temp_Country\"))\n\n# Let's plot disasters_world for sanity check (uncomment)\n# tmap::tm_shape(disasters_world) + \n#   tmap::tm_polygons(col = \"dis_F2019\")\n\n# now let's join all the datasets into one grand dataset :)\nclimate_action_data = dplyr::left_join(dis_temp, joined_df_clean,\n                                       by = c(\"dis_ISO3\" = \"co2_Country Code\"))\n# let's plot avergae yearly temperature in 2012!\ntmap::tm_shape(climate_action_data) + \n  tmap::tm_polygons(col = \"temp_2012\")\n\n\n\n\n\nAverage temperature in 2012\n\n\n\n\n\n\nData source 7 (World Values Survey)\nWorld Values Survey (WVS) is a global high-quality survey that collects nationally-representative data on values. The data is open to everyone to use for non-commercial purposes as long as data files themselves are not redistributed and correct citations provided. Given terms of use, we ask you to download data for waves 4-7 from their website and the recommended format is .sav (for SPSS).\n\n# read waves 4-7\nwvs4 = foreign::read.spss(\"data/WV4_Data_spss_v20201117.sav\",\n                          to.data.frame = TRUE) # import as dataframe (otherwise it will be a list)\nwvs5 = foreign::read.spss(\"data/WV5_Data_Spss_v20180912.sav\",\n                          to.data.frame = TRUE)\nwvs6 = foreign::read.spss(\"data/WV6_Data_sav_v20201117.sav\", \n                          to.data.frame = TRUE)\nwvs7 = foreign::read.spss(\"data/WVS_Cross-National_Wave_7_spss_v4_0.sav\", \n                          to.data.frame = TRUE)\n\n\nSubsetting\nEach WVS dataset has loads of variables, yet not all of them interest us at this point.\nWe will extract the following variables:\n\ncountry\nviews on the importance of protecting environment vs. economic growth (we use this question as a proxy for climate change attitude)\nsex (note: sex rather than gender is used in the surveys)\nage\neducation\nsocial class\nincome level\n\nAlso we will give more understandable column names.\n\nwvs7_sub = wvs7 |> dplyr::select(B_COUNTRY_ALPHA, Q111, Q260, X003R2, Q275R, Q287, Q288R)\ncolnames(wvs7_sub) = c(\"country_7\", \"env_7\", \"sex_7\", \"age_7\", \"education_7\", \"class_7\", \"income_7\")\n\nwvs6_sub = wvs6 |> dplyr::select(B_COUNTRY_ALPHA, V81, V240, X003R2, V248, V238, V239)\ncolnames(wvs6_sub) = c(\"country_6\", \"env_6\", \"sex_6\", \"age_6\", \"education_6\", \"class_6\", \"income_6\")\n\nwvs5_sub = wvs5 |> dplyr::select(V2, V104, V235, V237, V238, V252, V253) # I cannot believe this dataset doesn't have ISO code...\ncolnames(wvs5_sub) = c(\"country_5\", \"env_5\", \"sex_5\", \"age_5\", \"education_5\", \"class_5\", \"income_5\")\n\nwvs4_sub = wvs4 |> dplyr::select(B_COUNTRY_ALPHA, V36, V223, V225R2, V226, V235, V236)\ncolnames(wvs4_sub) = c(\"country_4\", \"env_4\", \"sex_4\", \"age_4\", \"education_4\", \"class_4\", \"income_4\")\n\n\n\nRecoding and joining\nIn this section we will change variable values from character to numeric in the hope of easing the interpretation. Then we will join all four waves into one dataset.\n\n# find out max length of each, we'll use this information to create NA cells, so length of all datasets is the same\n# then we'll be able to join them easily\n\nmax_length = max(c(nrow(wvs4_sub), nrow(wvs5_sub), nrow(wvs6_sub), nrow(wvs7_sub)))\nmax_length # wave 6 has most obervations\n\nwvs7_sub = wvs7_sub |> \n  dplyr::mutate (env_7_num = env_7 |> as.numeric(),\n                # env_7_num = c(wvs7_sub$env_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                sex_7_num = sex_7 |> as.numeric(),\n                # sex_7_num = c(wvs7_sub$sex_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                age_7_num = age_7 |> as.numeric(),\n                # age_7_num = c(wvs7_sub$age_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                education_7_num = education_7 |> as.numeric(),\n                # education_7_num = c(wvs7_sub$education_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                income_7_num = income_7 |> as.numeric(),\n                # income_7_num = c(wvs7_sub$income_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                )\n\nwvs7_new = data.frame(env_7_num = c(wvs7_sub$env_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                      sex_7_num = c(wvs7_sub$sex_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                      age_7_num = c(wvs7_sub$age_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                      education_7_num = c(wvs7_sub$education_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                      income_7_num = c(wvs7_sub$income_7_num, rep(NA, max_length - nrow(wvs7_sub))),\n                      country_7 = c(wvs7_sub$country_7, rep(NA, max_length - nrow(wvs7_sub)))\n                      )\n\nwvs6_sub = wvs6_sub |> \n  dplyr::mutate(env_6_num = env_6 |> as.numeric() |> as.factor(),\n                sex_6_num = sex_6 |> as.numeric(),\n                age_6_num = age_6 |> as.numeric(),\n                education_6_num = education_6 |> as.numeric(),\n                income_6_num = income_6 |> as.numeric())\n\nwvs6_new = data.frame(env_6_num = c(wvs6_sub$env_6_num, rep(NA, max_length - nrow(wvs6_sub))),\n                      sex_6_num = c(wvs6_sub$sex_6_num, rep(NA, max_length - nrow(wvs6_sub))),\n                      age_6_num = c(wvs6_sub$age_6_num, rep(NA, max_length - nrow(wvs6_sub))),\n                      education_6_num = c(wvs6_sub$education_6_num, rep(NA, max_length - nrow(wvs6_sub))),\n                      income_6_num = c(wvs6_sub$income_6_num, rep(NA, max_length - nrow(wvs6_sub))),\n                      country_6 = c(wvs6_sub$country_6, rep(NA, max_length - nrow(wvs6_sub)))\n)\n\nwvs5_sub = wvs5_sub |> \n  dplyr::mutate(env_5_num = env_5 |> as.numeric() |> as.factor(),\n                sex_5_num = sex_5 |> as.numeric(),\n                age_5_num = age_5 |> as.numeric() |> cut(breaks = c(0, 29, 49, 120), labels = c(1,2,3)),\n                education_5_num = education_5 |> as.numeric(),\n                income_5_num = income_5 |> as.numeric())\n\n# for some reason countries are returned as levels in integer form (e.g. 1) rather than character (i.e. \"Andora\"),\n# so we'll need to do tricks here :)\nunique_vals = wvs5_sub$country_5 |> unique() |> as.character()\nwvs5_new = data.frame(env_5_num = c(wvs5_sub$env_5_num, rep(NA, max_length - nrow(wvs5_sub))),\n                      sex_5_num = c(wvs5_sub$sex_5_num, rep(NA, max_length - nrow(wvs5_sub))),\n                      age_5_num = c(wvs5_sub$age_5_num, rep(NA, max_length - nrow(wvs5_sub))),\n                      education_5_num = c(wvs5_sub$education_5_num, rep(NA, max_length - nrow(wvs5_sub))),\n                      income_5_num = c(wvs5_sub$income_5_num, rep(NA, max_length - nrow(wvs5_sub))),\n                      country_5 = c(wvs5_sub$country_5, rep(NA, max_length - nrow(wvs5_sub))) |> factor(labels = unique_vals)\n)\n\n\nwvs4_sub = wvs4_sub |> \n  dplyr::mutate(env_4_num = env_4 |> as.numeric() |> as.factor(),\n                sex_4_num = sex_4 |> as.numeric(),\n                age_4_num = age_4 |> as.numeric(),\n                education_4_num = education_4 |> as.numeric(),\n                income_4_num = income_4 |> as.numeric())\n\nwvs4_new = data.frame(env_4_num = c(wvs4_sub$env_4_num, rep(NA, max_length - nrow(wvs4_sub))),\n                      sex_4_num = c(wvs4_sub$sex_4_num, rep(NA, max_length - nrow(wvs4_sub))),\n                      age_4_num = c(wvs4_sub$age_4_num, rep(NA, max_length - nrow(wvs4_sub))),\n                      education_4_num = c(wvs4_sub$education_4_num, rep(NA, max_length - nrow(wvs4_sub))),\n                      income_4_num = c(wvs4_sub$income_4_num, rep(NA, max_length - nrow(wvs4_sub))),\n                      country_4 = c(wvs4_sub$country_4, rep(NA, max_length - nrow(wvs4_sub)))\n)\n\n\n# sanity check that levels match numeric values (uncomment)\n# wvs7_sub$age_7 |> unique()\n# wvs7_sub$age_7_num |> unique()\n# wvs6_sub$age_6 |> unique()\n# wvs6_sub$age_6_num |> unique()\n# wvs5_sub$age_5 |> unique()\n# wvs5_sub$age_5_num |> unique()\n# wvs4_sub$age_4 |> unique()\n# wvs4_sub$age_4_num |> unique()\n\n\n\n\nData source 8 (OpenStreetMap)\nOpenStreetMap data is a global project aiming to create a free map of the world through crowdsourcing. It contains data on various data on buildings and roads. We used OSM data to collect the count of renewable energy generators. For historical data we relied on ohsome dashboard.\n\n\n\n\nAn example of retrieving the total count of renewable energy generators in Poland from 2007 to 2022\n\n\n\nIt is important to note that OSM data might not be complete, with some countries having more objects mapped that others. For example, developing countries, such as Iran, might have just started to consider the crowdsourced data and examine OSM data quality while in Germany the community of mappers is large. Also OSM developed as a road mapping project, therefore other objects (such as renewable energy generators) could have started being mapped later at different rates in different regions. Therefore, it is crucial to consider OSM data with a pinch of salt when analysing results. Nevertheless we still consider that OSM data can provide interesting insights and provide data that otherwise would not be freely and openly accessible."
  }
]